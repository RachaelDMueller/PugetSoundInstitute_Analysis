{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db0668f-a8e6-4c5b-b882-c1298d5bb509",
   "metadata": {},
   "source": [
    "# Station time series plot\n",
    "Dev note: Consider using dictionary for lat/lon locations, e.g.\n",
    "```\n",
    "BBAY_TS_loc = {\n",
    "    'NOAA_46118':[48.724, -122.576]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe27d1a7-fdbf-4cd4-8999-4c2ab0f41ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../scripts/')\n",
    "import xarray\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pathlib\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ssm_utils import find_closest_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ef082c-80a1-44d6-8c98-50c6a95c3903",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rc('font', size=11)\n",
    "# some of the following may be repetetive but can also be set relative to the font value above \n",
    "#    (eg \"xx-small, x-small,small, medium, large, x-large, xx-large, larger, or smaller\"; see link above for details)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "mpl.rc('legend', fontsize=12)\n",
    "mpl.rc('axes', titlesize=16)\n",
    "mpl.rc('axes', labelsize=12)\n",
    "mpl.rc('figure', titlesize=16)\n",
    "mpl.rc('text', usetex=False)\n",
    "mpl.rc('font', family='sans-serif', weight='normal', style='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b898ee8a-f87c-480a-abfd-ebd4c58c842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../etc/SSM_config.yaml', 'r') as file:\n",
    "    ssm = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2facdf90-c7d4-4488-a799-a227b24b0a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id=[\n",
    "    'NOAA Station 46118', \n",
    "    'BHAM-Bay Low DO', \n",
    "    'Birch Bay', \n",
    "    'Birch Bay (Point Whitehorn)',\n",
    "    'Cherry Point', \n",
    "    'Eastsound']\n",
    "station_lat=np.array([48.724, 48.767422, 48.898880, 48.895273, 48.868451, 48.684406])\n",
    "station_lon=np.array([-122.57, -122.575792, -122.781905, -122.805067, -122.780400, -122.898953])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b968254-9f72-4fa3-9bee-9cbbe5c6929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id, df_index, st_x, st_y = find_closest_node(\n",
    "    ssm['shapefile_path'], station_lat, station_lon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71079884-8313-420c-9d5d-4ac94ba1e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reshape FVCOM array\n",
    "def reshape_fvcom(fvcom_timeIJK, reshape_type):\n",
    "    \"\"\" Reorganize the 2D FVCOM output from 2-dimensions of (time,nodes)\n",
    "    to a format that allows for daily, yearly, or depth calculations. \n",
    "    \n",
    "    param float fvcom_timeIJK: FVCOM_v2.7ecy output array in dimension of 8760x160120.\n",
    "    param string reshape_type: ['days','levels','dayslevels']\n",
    "    return: Reorganized array\n",
    "    \"\"\"\n",
    "    ti,ni = fvcom_timeIJK.shape\n",
    "    print(ti,ni)\n",
    "    # Error handling\n",
    "    if reshape_type not in ['days','levels','dayslevels']:\n",
    "        raise ValueError(\n",
    "            \"options for reshape_type are: 'days','levels','dayslevels'\"\n",
    "        )\n",
    "    \n",
    "    # Reshaping\n",
    "    if reshape_type == 'days':\n",
    "        if (ti != 8760):\n",
    "            raise TypeError(\n",
    "                \"FVCOM array must have a time dimension of 8760\"\n",
    "            )\n",
    "        fvcom_reshaped = numpy.reshape(\n",
    "            fvcom_timeIJK[:,:].data, (365,24,ni)\n",
    "        )\n",
    "    elif reshape_type == 'levels':\n",
    "        if (ni != 160120):\n",
    "            raise TypeError(\n",
    "                \"FVCOM array must have a node dimension of 160120\"\n",
    "            )\n",
    "        fvcom_reshaped = numpy.reshape(\n",
    "            fvcom_timeIJK[:,:].data, (ti,16012,10)\n",
    "        )\n",
    "    elif reshape_type == 'dayslevels':\n",
    "        if (ti != 8760) or (ni != 160120):\n",
    "            raise TypeError(\n",
    "                \"FVCOM array size must be 8760 x 160120\"\n",
    "            )\n",
    "        fvcom_reshaped = numpy.reshape(\n",
    "            fvcom_timeIJK[:,:].data, (365,24,16012,10)\n",
    "        )\n",
    "        \n",
    "    return fvcom_reshaped\n",
    "def calc_fvcom_stat(fvcom_output, stat_type, axis):\n",
    "    \"\"\" Extract model output at nodes by level. \n",
    "    \n",
    "    param float fvcom_output: FVCOM_v2.7ecy output array in dimensions of time x 160120.\n",
    "    param float stat_type: 'min','mean'.\n",
    "    param int axis: Integer from 0 to ndims(fvcom_output)\n",
    "    \n",
    "    return: stat of model output across specified axis (axs)\n",
    "    \"\"\"\n",
    "    fvcom_stat = getattr(numpy,stat_type)(fvcom_output,axis=axis)\n",
    "    \n",
    "    return fvcom_stat\n",
    "\n",
    "def extract_fvcom_level(gdf, fvcom_timeIJK, LevelNum):\n",
    "    \"\"\" Extract model output at nodes by level. \n",
    "    \n",
    "    param dataframe gdf: geopandas dataframe of FVCOM nodes from 2D planar nodes\n",
    "        with dimensions of 16012.\n",
    "    param float fvcom_timeIJK: 3D-FVCOM output in dimensions of time x 160120.\n",
    "    param int LevelNum: Integer from 1 (surface) to 10 (bottom)\n",
    "    \n",
    "    return fvcom_nodeIDs: model output at level in dimension of time x 16012\n",
    "    \"\"\"\n",
    "    if LevelNum not in range(1,11):\n",
    "        raise ValueError(\"fvcom_LevelNum must be an integer value from 1-10\")\n",
    "\n",
    "    try:\n",
    "        node_ids = gdf['node_id'].to_numpy()\n",
    "    except:\n",
    "        raise AttributeError(\"missing 'node_id' column in dataframe\")\n",
    "        \n",
    "    ijk_index = node_ids * 10 - (11-LevelNum)\n",
    "    # get DO values at each level\n",
    "    fvcom_nodeIDs = fvcom_timeIJK[:,ijk_index]\n",
    "    # if ds['Var_10'] is passed in: \n",
    "    # fvcom_nodeIDs = fvcom_timeIJK[:,:].data[:,ijk_index]\n",
    "    \n",
    "    return fvcom_nodeIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb9aa40-a616-4cff-997c-f4fd7e050120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with all variable options (these can be expanded)\n",
    "variable_name_list=['DO','NH3','NO3','NPP','Temp','Salinity']\n",
    "parameter_ID_list=['Var_10','Var_14','Var_15','Var_17','Var_18','Var_19']\n",
    "model_output_name = {\n",
    "    variable_name_list[i]: parameter_ID_list[i] for i in range(len(variable_name_list))\n",
    "}\n",
    "\n",
    "# Define the variable that we want to plot\n",
    "variable_name = \"DO\" \n",
    "\n",
    "# Define directory for saving netcdf output\n",
    "output_directory = pathlib.Path('/mmfs1/gscratch/ssmc/USRS/PSI/Rachael/output/TS')\n",
    "\n",
    "# Define locations for different scenarios\n",
    "root_dir = pathlib.Path('/mmfs1/gscratch/ssmc/USRS/PSI/Adi/BS_WQM/')\n",
    "data_paths=numpy.array(\n",
    "    [root_dir/'2014_SSM4_WQ_exist_orig/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_ref_orig/hotstart/outputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c72d77e-c3f1-4d65-a4a8-4767e80e86eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8760 160120\n",
      "365 160120\n"
     ]
    }
   ],
   "source": [
    "si = 0 # choose first directory = Existing\n",
    "variable_name = 'DO'\n",
    "\n",
    "scenario_name=str(data_paths[si]).split('/')[-3]\n",
    "# output netcdf filename\n",
    "output_file = output_directory/f'{scenario_name}_{variable_name}.nc'\n",
    "# input netcdf filename\n",
    "file_path=data_paths[si]/'s_hy_base000_pnnl007_nodes.nc'\n",
    "# load variable into xarray and calculate daily min.\n",
    "with xarray.open_dataset(file_path) as ds:\n",
    "    dailyDO = reshape_fvcom(\n",
    "        ds[model_output_name[variable_name]][:,:].data, \n",
    "        'days'\n",
    "    ) #return (365x24xnodes)\n",
    "    # calculate daily minimum\n",
    "    dailyDO_tmin = calc_fvcom_stat(dailyDO, 'min', axis=1)\n",
    "    # reshape to levels\n",
    "    dailyDO_tmin_rshp = reshape_fvcom(dailyDO_tmin, 'levels')\n",
    "    # calculate minimum across depth levels\n",
    "    dailyDO_tmin_zmin = calc_fvcom_stat(dailyDO_tmin_rshp, 'min', axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0aaa0f-0c56-4256-ad9e-1e6e1a7d8b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>Basin</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1249</td>\n",
       "      <td>SJF_Admiralty</td>\n",
       "      <td>POLYGON ((-13875002.725 6177241.606, -13875563...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1336</td>\n",
       "      <td>SJF_Admiralty</td>\n",
       "      <td>POLYGON ((-13871902.847 6172073.657, -13872526...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id          Basin                                           geometry\n",
       "0     1249  SJF_Admiralty  POLYGON ((-13875002.725 6177241.606, -13875563...\n",
       "1     1336  SJF_Admiralty  POLYGON ((-13871902.847 6172073.657, -13872526..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kevin's shapefile\n",
    "shapefile_path = pathlib.Path(\n",
    "    '/mmfs1/gscratch/ssmc/USRS/PSI/Rachael/projects/KingCounty/KingCounty-Rachael/kevin_shapefiles'\n",
    ")/'SSMGrid2_tce.shp'\n",
    "gdf_k = gpd.read_file(shapefile_path)\n",
    "gdf_k = gdf_k.loc[:, ('tce','Basin','geometry')]\n",
    "gdf_k=gdf_k.rename(columns={'tce':'node_id'})\n",
    "# Extract SOG_Bays from Kevin's shapefile \n",
    "gdf_SOG_Nbays = gdf_k.loc[gdf_k['Basin']=='SOG_Bays']\n",
    "gdf = gdf_SOG_Nbays.copy()\n",
    "gdf_k.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c92c6423-2e82-496d-a299-5a806504ecb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3510 is out of bounds for axis 0 with size 365",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dailyDO_tmin_zmin_SOG \u001b[38;5;241m=\u001b[39m \u001b[43mdailyDO_tmin_zmin\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnode_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m dailyDO_tmin_zmin_SOG\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3510 is out of bounds for axis 0 with size 365"
     ]
    }
   ],
   "source": [
    "dailyDO_tmin_zmin_SOG = dailyDO_tmin_zmin[gdf['node_id']-1]\n",
    "\n",
    "dailyDO_tmin_zmin_SOG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf710b-946d-4ae4-9a70-4891d0e380ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "gdir = pathlib.Path(\n",
    "    '/mmfs1/gscratch/ssmc/USRS/PSI/Rachael/projects/CWA/CleanWaterAlliance/dev/minDO/')\n",
    "fs_t=14\n",
    "fs_a=12\n",
    "cax={}\n",
    "gdf['minDO'] = dailyDO_tmin_zmin_SOG   \n",
    "fig, axs = plt.subplots(1,1, figsize = (8,6))\n",
    "# create `cax` for the colorbar\n",
    "divider = make_axes_locatable(axs)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "gdf.plot('DOlt5', ax=axs, cax=cax, legend=True,vmin=1, vmax=150)\n",
    "cax.set_ylabel(f'Days with DO < {threshold}[mg/l]',fontsize=14)\n",
    "axs.set(yticklabels='', xticklabels='')\n",
    "#axs.set_title(f'min DO (day={time_index})\\nall levels', fontsize=fs_t)\n",
    "#plt.savefig(gdir/f'SOGNB_minDO_lt{threshold}.jpeg',dpi=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
