{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba1d6263-aba1-4a7f-b560-94867533fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "import numpy\n",
    "import pandas\n",
    "import pathlib\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "791eed69-daef-4519-82d8-dfef361d4041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphics style\n",
    "plt.style.use(r\"/mmfs1/gscratch/ssmc/USRS/PSI/Rachael/projects/KingCounty/KingCounty-Rachael/style_files/presentation_matplotlibrc.template\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95338572-8107-4d2f-bc80-ff37e69db805",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions\n",
    "1. Reshape FVCOM array (reshape_fvcom)\n",
    "2. Extract model output by depth level (extract_fvcom_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a73b2762-6d27-4fac-a76d-1991a52925ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reshape FVCOM array\n",
    "def reshape_fvcom(fvcom_timeIJK, reshape_type):\n",
    "    \"\"\" Reorganize the 2D FVCOM output from 2-dimensions of (time,nodes)\n",
    "    to a format that allows for daily, yearly, or depth calculations. \n",
    "    \n",
    "    param float fvcom_timeIJK: FVCOM_v2.7ecy output array in dimension of 8760x160120.\n",
    "    param string reshape_type: ['days','levels','dayslevels']\n",
    "    return: Reorganized array\n",
    "    \"\"\"\n",
    "    ti,ni = fvcom_timeIJK.shape\n",
    "    print(ti,ni)\n",
    "    # Error handling\n",
    "    if reshape_type not in ['days','levels','dayslevels']:\n",
    "        raise ValueError(\n",
    "            \"options for reshape_type are: 'days','levels','dayslevels'\"\n",
    "        )\n",
    "    \n",
    "    # Reshaping\n",
    "    if reshape_type == 'days':\n",
    "        if (ti != 8760):\n",
    "            raise TypeError(\n",
    "                \"FVCOM array must have a time dimension of 8760\"\n",
    "            )\n",
    "        fvcom_reshaped = numpy.reshape(\n",
    "            fvcom_timeIJK[:,:].data, (365,24,ni)\n",
    "        )\n",
    "    elif reshape_type == 'levels':\n",
    "        if (ni != 160120):\n",
    "            raise TypeError(\n",
    "                \"FVCOM array must have a node dimension of 160120\"\n",
    "            )\n",
    "        fvcom_reshaped = numpy.reshape(\n",
    "            fvcom_timeIJK[:,:].data, (ti,16012,10)\n",
    "        )\n",
    "    elif reshape_type == 'dayslevels':\n",
    "        if (ti != 8760) or (ni != 160120):\n",
    "            raise TypeError(\n",
    "                \"FVCOM array size must be 8760 x 160120\"\n",
    "            )\n",
    "        fvcom_reshaped = numpy.reshape(\n",
    "            fvcom_timeIJK[:,:].data, (365,24,16012,10)\n",
    "        )\n",
    "        \n",
    "    return fvcom_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b7f8ba-45c8-4b56-9ce5-abb2aa4d0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fvcom_level(gdf, fvcom_timeIJK, LevelNum):\n",
    "    \"\"\" Extract model output at nodes by level. \n",
    "    \n",
    "    param dataframe gdf: geopandas dataframe of FVCOM nodes from 2D planar nodes\n",
    "        with dimensions of 16012.\n",
    "    param float fvcom_timeIJK: 3D-FVCOM output in dimensions of time x 160120.\n",
    "    param int LevelNum: Integer from 1 (surface) to 10 (bottom)\n",
    "    \n",
    "    return fvcom_nodeIDs: model output at level in dimension of time x 16012\n",
    "    \"\"\"\n",
    "    if LevelNum not in range(1,11):\n",
    "        raise ValueError(\"fvcom_LevelNum must be an integer value from 1-10\")\n",
    "\n",
    "    try:\n",
    "        node_ids = gdf['node_id'].to_numpy()\n",
    "    except:\n",
    "        raise AttributeError(\"missing 'node_id' column in dataframe\")\n",
    "        \n",
    "    ijk_index = node_ids * 10 - (11-LevelNum)\n",
    "    # get DO values at each level\n",
    "    fvcom_nodeIDs = fvcom_timeIJK[:,ijk_index]\n",
    "    # if ds['Var_10'] is passed in: \n",
    "    # fvcom_nodeIDs = fvcom_timeIJK[:,:].data[:,ijk_index]\n",
    "    \n",
    "    return fvcom_nodeIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed18241b-7165-4f19-8105-507411b619db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fvcom_stat(fvcom_output, stat_type, axis):\n",
    "    \"\"\" Extract model output at nodes by level. \n",
    "    \n",
    "    param float fvcom_output: FVCOM_v2.7ecy output array in dimensions of time x 160120.\n",
    "    param float stat_type: 'min','mean'.\n",
    "    param int axis: Integer from 0 to ndims(fvcom_output)\n",
    "    \n",
    "    return: stat of model output across specified axis (axs)\n",
    "    \"\"\"\n",
    "    fvcom_stat = getattr(numpy,stat_type)(fvcom_output,axis=axis)\n",
    "    \n",
    "    return fvcom_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309410a9-9672-4f43-9dba-a82e3d19799a",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6754359-6050-4fb7-9476-9cd0c1fb4e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with all variable options (these can be expanded)\n",
    "variable_name_list=['DO','NH3','NO3','NPP','Temp','Salinity']\n",
    "parameter_ID_list=['Var_10','Var_14','Var_15','Var_17','Var_18','Var_19']\n",
    "model_output_name = {\n",
    "    variable_name_list[i]: parameter_ID_list[i] for i in range(len(variable_name_list))\n",
    "}\n",
    "\n",
    "# Define the variable that we want to plot\n",
    "variable_name = \"DO\" \n",
    "\n",
    "# Define directory for saving netcdf output\n",
    "output_directory = pathlib.Path('/mmfs1/gscratch/ssmc/USRS/PSI/Rachael/output/daily_min')\n",
    "\n",
    "# Define locations for different scenarios\n",
    "root_dir = pathlib.Path('/mmfs1/gscratch/ssmc/USRS/PSI/Adi/BS_WQM/')\n",
    "data_paths=numpy.array(\n",
    "    [root_dir/'2014_SSM4_WQ_exist_orig/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_ref_orig/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_rvr1.5_reg/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_rvr0.5_reg/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_rvr0.0_reg/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_rvr_ref_reg/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_rvr_mgt_reg/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_exist1.5_reg/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_exist0.5_reg/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_exist0.0_reg/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_exist_OBC2.0/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_exist_OBC1.5/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_exist_OBC0.5/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_exist_OBC0.0/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_exist_CoT_North/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_exist_CoT_CN/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_exist_CoT_Central/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_exist_CoT_Nth_wC/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_exist_CoT_Ctl_wC/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_exist_CoT_CN_wC/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_wwtp_3mgl_reg/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_wwtp0.0_reg/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_wwtp1.5_reg/hotstart/outputs',\n",
    "     root_dir/'2014_SSM4_WQ_wwtp0.5_reg/hotstart/outputs'\n",
    "    ]\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc77daad-967b-45bf-9dbf-fde570a74f13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get min daily DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d689e1b3-2b86-4db1-8f92-0fb1627e351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "si = 0 # choose first directory = Existing\n",
    "variable_name = 'DO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22643b46-3a5d-4b1a-b58d-d54fc84a98de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8760 160120\n",
      "365 160120\n"
     ]
    }
   ],
   "source": [
    "scenario_name=str(data_paths[si]).split('/')[-3]\n",
    "# output netcdf filename\n",
    "output_file = output_directory/f'{scenario_name}_{variable_name}.nc'\n",
    "# input netcdf filename\n",
    "file_path=data_paths[si]/'s_hy_base000_pnnl007_nodes.nc'\n",
    "# load variable into xarray and calculate daily min.\n",
    "with xarray.open_dataset(file_path) as ds:\n",
    "    dailyDO = reshape_fvcom(\n",
    "        ds[model_output_name[variable_name]][:,:].data, \n",
    "        'days'\n",
    "    ) #return (365x24xnodes)\n",
    "    # calculate daily minimum\n",
    "    dailyDO_tmin = calc_fvcom_stat(dailyDO, 'min', axis=1)\n",
    "    # reshape to levels\n",
    "    dailyDO_tmin_rshp = reshape_fvcom(dailyDO_tmin, 'levels')\n",
    "    # calculate minimum across depth levels\n",
    "    dailyDO_tmin_zmin = calc_fvcom_stat(dailyDO_tmin_rshp, 'min', axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d45c1cd9-a406-48d2-ad3a-2b674bcfec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of days with min DO difference < 2\n",
    "daily_minDO={}\n",
    "# save Existing\n",
    "daily_minDO['exist']=dailyDO_tmin_zmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d20467a-fa41-4462-b42a-9525a9d5b379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conc. of DO mg/l'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[model_output_name['DO']].attrs['FVCOM_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "224ea227-aea3-490e-8f9c-80b7fbc8771d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 16012)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailyDO_tmin_zmin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb8bb7-c7da-45d8-ba52-37ad7342da56",
   "metadata": {},
   "source": [
    "#### Plot 3-panel graphic of\n",
    "- minimum daily DO and across depth\n",
    "- minimum daily DO at bottom\n",
    "- difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89529cb2-ed18-425b-99ed-642fc81e2d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>depth</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4369</td>\n",
       "      <td>45.183998</td>\n",
       "      <td>POLYGON ((515282.150 5333310.800, 514957.767 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4370</td>\n",
       "      <td>51.813999</td>\n",
       "      <td>POLYGON ((515087.250 5334738.350, 515039.410 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id      depth                                           geometry\n",
       "0     4369  45.183998  POLYGON ((515282.150 5333310.800, 514957.767 5...\n",
       "1     4370  51.813999  POLYGON ((515087.250 5334738.350, 515039.410 5..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get nodes\n",
    "\n",
    "# #Ben's shapefile\n",
    "shapefile_path = pathlib.Path(\n",
    "    '/mmfs1/gscratch/ssmc/USRS/PSI/Rachael/projects/KingCounty/ssm-analysis/gis'\n",
    ")/'ssm filled domain nodes.shp'\n",
    "gdf_b = gpd.read_file(shapefile_path)\n",
    "gdf_b.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9957ec8f-6d41-4444-8662-4681240b6d9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "/mmfs1/gscratch/ssmc/USRS/PSI/Rachael/projects/KingCounty/KingCounty-Rachael/kevin_shapefiles/SSMGrid2_tce.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mfiona/_shim.pyx:83\u001b[0m, in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: /mmfs1/gscratch/ssmc/USRS/PSI/Rachael/projects/KingCounty/KingCounty-Rachael/kevin_shapefiles/SSMGrid2_tce.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Kevin's shapefile\u001b[39;00m\n\u001b[1;32m      2\u001b[0m shapefile_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mmfs1/gscratch/ssmc/USRS/PSI/Rachael/projects/KingCounty/KingCounty-Rachael/kevin_shapefiles\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m )\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSSMGrid2_tce.shp\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m gdf_k \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapefile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m gdf_k \u001b[38;5;241m=\u001b[39m gdf_k\u001b[38;5;241m.\u001b[39mloc[:, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtce\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBasin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m      7\u001b[0m gdf_k\u001b[38;5;241m=\u001b[39mgdf_k\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtce\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_id\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m~/.conda/envs/klone_jupyter/lib/python3.10/site-packages/geopandas/io/file.py:201\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     reader \u001b[38;5;241m=\u001b[39m fiona\u001b[38;5;241m.\u001b[39mopen\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fiona_env():\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m features:\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# In a future Fiona release the crs attribute of features will\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;66;03m# no longer be a dict, but will behave like a dict. So this should\u001b[39;00m\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;66;03m# be forwards compatible\u001b[39;00m\n\u001b[1;32m    206\u001b[0m         crs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    207\u001b[0m             features\u001b[38;5;241m.\u001b[39mcrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    208\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m features\u001b[38;5;241m.\u001b[39mcrs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mcrs\n\u001b[1;32m    209\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m features\u001b[38;5;241m.\u001b[39mcrs_wkt\n\u001b[1;32m    210\u001b[0m         )\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;66;03m# handle loading the bounding box\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/klone_jupyter/lib/python3.10/site-packages/fiona/env.py:408\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local\u001b[38;5;241m.\u001b[39m_env:\n\u001b[0;32m--> 408\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/klone_jupyter/lib/python3.10/site-packages/fiona/__init__.py:264\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     path \u001b[38;5;241m=\u001b[39m parse_path(fp)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 264\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menabled_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled_drivers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m schema:\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;66;03m# Make an ordered dict of schema properties.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/klone_jupyter/lib/python3.10/site-packages/fiona/collection.py:162\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m Session()\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n",
      "File \u001b[0;32mfiona/ogrext.pyx:540\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/_shim.pyx:90\u001b[0m, in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: /mmfs1/gscratch/ssmc/USRS/PSI/Rachael/projects/KingCounty/KingCounty-Rachael/kevin_shapefiles/SSMGrid2_tce.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Kevin's shapefile\n",
    "shapefile_path = pathlib.Path(\n",
    "    '/mmfs1/gscratch/ssmc/USRS/PSI/Rachael/projects/KingCounty/KingCounty-Rachael/kevin_shapefiles'\n",
    ")/'SSMGrid2_tce.shp'\n",
    "gdf_k = gpd.read_file(shapefile_path)\n",
    "gdf_k = gdf_k.loc[:, ('tce','Basin','geometry')]\n",
    "gdf_k=gdf_k.rename(columns={'tce':'node_id'})\n",
    "gdf_k.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f2e38-18fb-4e29-8623-d0e000e5b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_k.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d562c-9e13-4d8b-97f5-67e2c20b497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_k[['node_id','Basin']].groupby('Basin').count().rename(columns={'node_id':'node count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc1eb0-ca04-45db-90d0-abdedf69591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SOG_Bays from Kevin's shapefile \n",
    "gdf_SOG_Nbays = gdf_k.loc[gdf_k['Basin']=='SOG_Bays']\n",
    "gdf_SOG_Nbays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc217d9e-a10a-41c0-9757-eac1d8ea9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare South Sound \"tce\" to Ben's \"node_id\"\n",
    "gdf_ssound = gdf_k.loc[gdf_k['Basin']=='South Sound']\n",
    "print(gdf_ssound['node_id'].min(),gdf_ssound['node_id'].max(),gdf_b['node_id'].min(),gdf_b['node_id'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b3b6eb-1702-403b-b5d9-30bcdf5c5568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "223aabcc-bb08-459b-b262-e03601a10668",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot up min DO below Threshold for SOG & North Bays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df040086-2147-4b6b-8bd6-06b78f815312",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf_SOG_Nbays.copy()\n",
    "gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf8f6d9-386a-452f-a7e1-6804750064e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define min DO threshold\n",
    "threshold=4\n",
    "dailyDO_tmin_zmin_lt_thresh=numpy.count_nonzero(dailyDO_tmin_zmin<threshold,axis=0)\n",
    "# use node_id to select locations\n",
    "dailyDO_tmin_zmin_lt_thresh_SOG = dailyDO_tmin_zmin_lt_thresh[gdf['node_id']-1]\n",
    "dailyDO_tmin_zmin_lt_thresh_SOG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f50c30e-6ee8-48a1-bbb7-b44bc8b8870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "gdir = pathlib.Path(\n",
    "    '/mmfs1/gscratch/ssmc/USRS/PSI/Rachael/projects/CWA/CleanWaterAlliance/dev/minDO/')\n",
    "fs_t=14\n",
    "fs_a=12\n",
    "cax={}\n",
    "gdf['DOlt5'] = dailyDO_tmin_zmin_lt_thresh_SOG   \n",
    "fig, axs = plt.subplots(1,1, figsize = (8,6))\n",
    "# create `cax` for the colorbar\n",
    "divider = make_axes_locatable(axs)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "gdf.plot('DOlt5', ax=axs, cax=cax, legend=True,vmin=1, vmax=150)\n",
    "cax.set_ylabel(f'Days with DO < {threshold}[mg/l]',fontsize=14)\n",
    "axs.set(yticklabels='', xticklabels='')\n",
    "#axs.set_title(f'min DO (day={time_index})\\nall levels', fontsize=fs_t)\n",
    "plt.savefig(gdir/f'SOGNB_minDO_lt{threshold}.jpeg',dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b43259-8406-48a3-a7cd-b7c69835f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "si = 1 # choose first directory = Existing\n",
    "variable_name = 'DO'\n",
    "scenario_name=str(data_paths[si]).split('/')[-3]\n",
    "# output netcdf filename\n",
    "output_file = output_directory/f'{scenario_name}_{variable_name}.nc'\n",
    "# input netcdf filename\n",
    "file_path=data_paths[si]/'s_hy_base000_pnnl007_nodes.nc'\n",
    "# load variable into xarray and calculate daily min.\n",
    "with xarray.open_dataset(file_path) as ds:\n",
    "    dailyDO = reshape_fvcom(\n",
    "        ds[model_output_name[variable_name]][:,:].data, \n",
    "        'days'\n",
    "    ) #return (365x24xnodes)\n",
    "    # calculate daily minimum\n",
    "    dailyDO_tmin = calc_fvcom_stat(dailyDO, 'min', axis=1)\n",
    "    # reshape to levels\n",
    "    dailyDO_tmin_rshp = reshape_fvcom(dailyDO_tmin, 'levels')\n",
    "    # calculate minimum across depth levels\n",
    "    dailyDO_tmin_zmin = calc_fvcom_stat(dailyDO_tmin_rshp, 'min', axis=2)\n",
    "daily_minDO['ref']=dailyDO_tmin_zmin \n",
    "daily_minDO['diff']=daily_minDO['exist']-daily_minDO['ref']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123a0e4-95c1-49d7-8b57-ea7ff1820ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOG\n",
    "gdf = gdf_SOG_Nbays.copy()\n",
    "\n",
    "daily_minDO['diff_count']=numpy.count_nonzero((daily_minDO['exist']-daily_minDO['ref'])<-0.25,axis=0)\n",
    "# use node_id to select locations\n",
    "daily_minDOdiff_SOG = daily_minDO['diff_count'][gdf['node_id']-1]\n",
    "daily_minDOdiff_SOG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1beb9a6-aca1-4ce9-ad3a-0b15a9284c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_minDOdiff_SOG.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea53f00-4071-4d71-b139-8f5475105ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cax={}\n",
    "gdf['DOdiff'] = daily_minDOdiff_SOG   \n",
    "fig, axs = plt.subplots(1,1, figsize = (8,6))\n",
    "# create `cax` for the colorbar\n",
    "divider = make_axes_locatable(axs)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "gdf.plot('DOdiff', ax=axs, cax=cax, legend=True,vmin=1, vmax=50,cmap='rainbow')\n",
    "cax.set_ylabel(f'Days with DO (exist - ref) < -0/.25[mg/l]',fontsize=14)\n",
    "axs.set(yticklabels='', xticklabels='')\n",
    "#axs.set_title(f'min DO (day={time_index})\\nall levels', fontsize=fs_t)\n",
    "plt.savefig(gdir/f'SOGNB_minDO_Exist_minus_Ref_ltm0p25.jpeg',dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c748d30-4990-4dff-9b34-fbb9fefbdc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PS\n",
    "gdf = gdf_b.copy()\n",
    "\n",
    "daily_minDO['diff_count']=numpy.count_nonzero((daily_minDO['exist']-daily_minDO['ref'])<-0.25,axis=0)\n",
    "# use node_id to select locations\n",
    "daily_minDOdiff_SOG = daily_minDO['diff_count'][gdf['node_id']-1]\n",
    "daily_minDOdiff_SOG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271f751-4ed3-441b-9f38-f4979eaadb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "cax={}\n",
    "gdf['DOdiff'] = daily_minDOdiff_SOG   \n",
    "fig, axs = plt.subplots(1,1, figsize = (8,6))\n",
    "# create `cax` for the colorbar\n",
    "divider = make_axes_locatable(axs)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "gdf.plot('DOdiff', ax=axs, cax=cax, legend=True,vmin=1, vmax=50,cmap='rainbow')\n",
    "cax.set_ylabel(f'Days with DO (exist - ref) < -0.25[mg/l]',fontsize=14)\n",
    "axs.set(yticklabels='', xticklabels='')\n",
    "#axs.set_title(f'min DO (day={time_index})\\nall levels', fontsize=fs_t)\n",
    "plt.savefig(gdir/f'PS_minDO_Exist_minus_Ref_lt_m0p25.jpeg',dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d17dd-eda6-4dd0-b003-8ea1011f3bb1",
   "metadata": {},
   "source": [
    "### Plot 3-panel of min bottom DO, min DO across depth and difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15974c6f-0e50-49cb-abed-473874efbe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO={}\n",
    "# change name so that I can replicate this code more easily\n",
    "gdf = gdf_SOG_Nbays.copy()\n",
    "\n",
    "# the min across depth ought to have same node index as the shapefile\n",
    "DO['minDailyLevels'] = dailyDO_tmin_zmin[:,gdf['node_id']-1]\n",
    "# we need to map the nodes with all depths included to the shapefile nodes\n",
    "DO['minDailyBottom'] = extract_fvcom_level(gdf, dailyDO_tmin, LevelNum=10)\n",
    "DO['difference'] = DO['minDailyLevels'] - DO['minDailyBottom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17b692d-9877-4d6e-a82d-4cc4954db627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Some code to do colorbars properly\n",
    "# # create the colorbar\n",
    "# norm = colors.Normalize(vmin=0, vmax=1)\n",
    "# cbar = plt.cm.ScalarMappable(norm=norm, cmap='gist_earth_r')\n",
    "\n",
    "# # plot\n",
    "# fig, ax = plt.subplots(figsize=(15, 7))\n",
    "# gdf.plot(column='Index_power', cmap='gist_earth_r', legend=False, norm=norm, ax=ax) \n",
    "\n",
    "# # add colorbar\n",
    "# ax_cbar = fig.colorbar(cbar, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec44913-c1aa-4649-b00b-314a0006fbfa",
   "metadata": {},
   "source": [
    "# Plot SOG and N. Bays using Kevin's shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e30c4-a67c-438e-98d6-536708ae9056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "gdir = pathlib.Path(\n",
    "    '/mmfs1/gscratch/ssmc/USRS/PSI/Rachael/projects/CWA/CleanWaterAlliance/dev/minDO/SOG')\n",
    "fig, axs = plt.subplots(1,3, figsize = (16,8))\n",
    "fs_t=14\n",
    "fs_a=12\n",
    "cax={}\n",
    "\n",
    "for time_index in range(0,1):#365):\n",
    "    gdf['minDailyLevels'] = DO['minDailyLevels'][time_index]\n",
    "    gdf['minDailyBottom'] = DO['minDailyBottom'][time_index]\n",
    "    gdf['difference'] = DO['difference'][time_index]\n",
    "    \n",
    "    fig, axs = plt.subplots(1,3, figsize = (16,8))\n",
    "    # create `cax` for the colorbar\n",
    "    for axs_ind in range(0,3):\n",
    "        divider = make_axes_locatable(axs[axs_ind])\n",
    "        cax[axs_ind] = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "        #cax[axs_ind].set_yticklabels({'fontsize': 14})\n",
    "        #cax[axs_ind].set_ylabel('Conc. of DO mg/l',fontsize=14)\n",
    "\n",
    "    gdf.plot('minDailyLevels', ax=axs[0], cax=cax[0], legend=True,vmin=1, vmax=10)\n",
    "    cax[0].set_ylabel(ds[model_output_name['DO']].attrs['FVCOM_Name'],fontsize=14)\n",
    "    gdf.plot('minDailyBottom', ax=axs[1], cax=cax[1], legend=True,vmin=1, vmax=10)\n",
    "    cax[1].set_ylabel(ds[model_output_name['DO']].attrs['FVCOM_Name'],fontsize=14)\n",
    "    gdf.plot('difference', ax=axs[2], cax=cax[2], legend=True, vmin=-4, vmax=0)\n",
    "    cax[2].set_ylabel('DO difference [mg/l]',fontsize=14)\n",
    "    for idx in [0,1,2]:\n",
    "        axs[idx].set(yticklabels='', xticklabels='')\n",
    "    axs[0].set_title(f'min DO (day={time_index})\\nall levels', fontsize=fs_t)\n",
    "    axs[1].set_title(f'min DO (day={time_index})\\nbottom level', fontsize=fs_t)\n",
    "    axs[2].set_title(f'min DO (day={time_index})\\nall - bottom', fontsize=fs_t)\n",
    "    #plt.savefig(gdir/f'{time_index:03d}.jpeg',dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45d1321-712e-478f-befe-ce8d1f5438c9",
   "metadata": {},
   "source": [
    "# Plot S. Sound using Ben's shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f7945-a436-4b93-b01a-080f9008236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf_b.copy()\n",
    "DO={}\n",
    "\n",
    "# the min across depth ought to have same node index as the shapefile\n",
    "DO['minDailyLevels'] = dailyDO_tmin_zmin[:,gdf['node_id']-1]\n",
    "# we need to map the nodes with all depths included to the shapefile nodes\n",
    "DO['minDailyBottom'] = extract_fvcom_level(gdf, dailyDO_tmin, LevelNum=10)\n",
    "DO['difference'] = DO['minDailyLevels'] - DO['minDailyBottom']\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "gdir = pathlib.Path(\n",
    "    '/mmfs1/gscratch/ssmc/USRS/PSI/Rachael/projects/CWA/CleanWaterAlliance/dev/minDO/PS')\n",
    "fig, axs = plt.subplots(1,3, figsize = (16,8))\n",
    "fs_t=14\n",
    "fs_a=12\n",
    "cax={}\n",
    "for time_index in range(0,1):#365):\n",
    "    gdf['minDailyLevels'] = DO['minDailyLevels'][time_index]\n",
    "    gdf['minDailyBottom'] = DO['minDailyBottom'][time_index]\n",
    "    gdf['difference'] = DO['difference'][time_index]\n",
    "    \n",
    "    fig, axs = plt.subplots(1,3, figsize = (16,8))\n",
    "    # create `cax` for the colorbar\n",
    "    for axs_ind in range(0,3):\n",
    "        divider = make_axes_locatable(axs[axs_ind])\n",
    "        cax[axs_ind] = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "        #cax[axs_ind].set_yticklabels({'fontsize': 14})\n",
    "        #cax[axs_ind].set_ylabel('Conc. of DO mg/l',fontsize=14)\n",
    "\n",
    "    gdf.plot('minDailyLevels', ax=axs[0], cax=cax[0], legend=True,vmin=1, vmax=10)\n",
    "    cax[0].set_ylabel(ds[model_output_name['DO']].attrs['FVCOM_Name'],fontsize=14)\n",
    "    gdf.plot('minDailyBottom', ax=axs[1], cax=cax[1], legend=True,vmin=1, vmax=10)\n",
    "    cax[1].set_ylabel(ds[model_output_name['DO']].attrs['FVCOM_Name'],fontsize=14)\n",
    "    gdf.plot('difference', ax=axs[2], cax=cax[2], legend=True, vmin=-4, vmax=0)\n",
    "    cax[2].set_ylabel('DO difference [mg/l]',fontsize=14)\n",
    "    for idx in [0,1,2]:\n",
    "        axs[idx].set(yticklabels='', xticklabels='')\n",
    "    axs[0].set_title(f'min DO (day={time_index})\\nall levels', fontsize=fs_t)\n",
    "    axs[1].set_title(f'min DO (day={time_index})\\nbottom level', fontsize=fs_t)\n",
    "    axs[2].set_title(f'min DO (day={time_index})\\nall - bottom', fontsize=fs_t)\n",
    "    #plt.savefig(gdir/f'{time_index:03d}.jpeg',dpi=150,bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488d7e03-1a6e-44da-9066-14cde81f1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf['node_id'].shape)\n",
    "print(fvcom_nodeIDs.shape)\n",
    "print(dailyDO_tmin_zmin.shape) # minimum over 24-hrs and all depth levels\n",
    "print(dailyDO_tmin_rshp[:,:,9].shape) #bottom level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf92edf-141e-455a-a7b4-52b6192ae96e",
   "metadata": {},
   "source": [
    "## Start simple: Extract information for one variable and one scenario\n",
    "\n",
    "coded in a way that this can easily be adapted to many scenarios and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f00e65-107f-45a1-a727-f1339577639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# use range to easily adapt to multiple scenarios but only select the first one here\n",
    "for si in range(0, 1):\n",
    "    print(data_paths[si])\n",
    "    scenario_name=str(data_paths[si]).split('/')[-3]\n",
    "    # output netcdf filename\n",
    "    output_file = output_directory/f'{scenario_name}_{variable_name}.nc'\n",
    "    # input netcdf filename\n",
    "    file_path=data_paths[si]/'s_hy_base000_pnnl007_nodes.nc'\n",
    "    # load variable into xarray and calculate daily min.\n",
    "    # NOTE: For ease, I use original method with numpy and pandas but \n",
    "    #    it may be worth exploring ways to calculate the min in xarray format\n",
    "    with xarray.open_dataset(file_path) as ds:\n",
    "        model_output_daily=numpy.reshape(\n",
    "            ds[model_output_name[variable_name]][:,:].data, (365,24,160120)\n",
    "        )\n",
    "        model_output_daily_min=numpy.min(model_output_daily,axis=1)\n",
    "        model_output_daily_min_pd=pandas.DataFrame(model_output_daily_min)\n",
    "        # create a new xarray with min daily values\n",
    "        model_output_daily_min_xr = xarray.DataArray(model_output_daily_min_pd)\n",
    "        # rename the coordinates so they are human-readable\n",
    "        model_output_daily_min_xr=model_output_daily_min_xr.rename(\n",
    "            {'dim_0':'time_in_days', 'dim_1':'node_id'}\n",
    "        )\n",
    "        model_output_daily_min_xr.to_netcdf(output_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82aafdb-a23d-408c-bacd-3ae0e379975b",
   "metadata": {},
   "source": [
    "### Ben's method of extracting the bottom depth values.  From his [DO ecolocy extraction.ipynb](https://github.com/bedaro/ssm-analysis/blob/main/DO%20ecology%20extraction.ipynb) notebook:\n",
    "\n",
    "IJK is a representation of the 10 depth points per node, zero-indexed, so to get the bottom points we need to multiply the node number minus 1 by 10 and add 9. For instance, if we wanted the bottom point of node 1 we'd get IJK index 9, and for node 2 we'd get IJK index 19. This simplifies to the expression in the cell below.\n",
    "```\n",
    "# read in 2D nodes from shapefile\n",
    "domain_nodes = gpd.read_file(domain_nodes_shp)\n",
    "domain_nodes.set_index('node_id', inplace=True)\n",
    "# map 2D \"node_id\" to 3D bottom depth \"node_id\"\n",
    "node_ids = domain_nodes.sort_index().index.to_numpy()\n",
    "ijk_index = node_ids * 10 - 1\n",
    "display(ijk_index)\n",
    "bottom_output = ds[model_output_name[variable_name]][:,:].data[:,ijk_index]\n",
    "```\n",
    "In this method, the bottom level nodes are extracted into a 1D vector \n",
    "### Su Kyong's code for reshaping output into 24-hr days and depth-layers\n",
    "```\n",
    "np.reshape(3D_data,(365,24,16012,10))\n",
    "```\n",
    "In this method, the nodes are reshaped into a matrix with dimensions 365x24x16012x10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250081e-7740-4ca2-ab24-b4aeaa431ff2",
   "metadata": {},
   "source": [
    "### PROOF OF CONCEPT: plot the annually-averaged DO for each of the ten layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1849f-9bcf-4d55-8c40-64e06363ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output=numpy.reshape(\n",
    "    ds[model_output_name['DO']][:,:].data, (365*24,16012,10)\n",
    ")\n",
    "model_output_yrAvg=numpy.mean(model_output,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eacd396-6c15-4352-a7e0-90e856541865",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_yrAvg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79626400-bf5b-41b3-afb7-c37b952e5945",
   "metadata": {},
   "source": [
    "These are the yearly-averaged values over the entire grid but Ben's shapefile is just for the Puget Sound.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f5a14-16d9-45f9-bbf2-8c74e3f2bbda",
   "metadata": {},
   "source": [
    "## Sample graphic (experiment with bathymetry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a81ecbc-15a0-453d-8357-63020446f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "shapefile_path = pathlib.Path(\n",
    "    '/mmfs1/gscratch/ssmc/USRS/PSI/Rachael/projects/CWA/ssm-analysis/gis'\n",
    ")/'ssm filled domain nodes.shp'\n",
    "gdf = gpd.read_file(shapefile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c006c4f7-2552-462a-ab37-8b1da8b14be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ff7d8-51f8-4157-a322-23362708e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74dbed2-1fa2-451f-a8e8-e044b56b913b",
   "metadata": {},
   "source": [
    "### Create vectors with node_ids that will map the 3D output to the 2D shapefile node_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e5489-746b-4dd8-ad0d-0d067118d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "node_ids = gdf['node_id'].to_numpy()\n",
    "ijk_index={}\n",
    "DO={}\n",
    "for depth_layer in range(1,11):\n",
    "    print(depth_layer)\n",
    "    DO[depth_layer]=extract_fvcom_level(\n",
    "        ds[model_output_name['DO']], \n",
    "        node_ids, \n",
    "        depth_layer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1411e752-407d-452d-9e69-81f3e4ad4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "node_ids = gdf['node_id'].to_numpy()\n",
    "ijk_index={}\n",
    "DO={}\n",
    "for depth_layer in range(1,11):\n",
    "    print(depth_layer)\n",
    "    ijk_index[depth_layer] = node_ids * 10 - (11-depth_layer)\n",
    "    # get DO values at each level\n",
    "    DO[depth_layer] = ds[model_output_name['DO']][:,:].data[:,ijk_index[depth_layer]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc91937-6920-4ef0-ad77-1cf0174210d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### We have 10 depth-layers of yearly data for 6120 nodes\n",
    "Take yearly-average of DO for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3531209-31ea-4946-971d-4050ddbbe1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(1,10, figsize = (48,8))\n",
    "for level in range(1,11):\n",
    "    gdf.plot(f'DO_yrAvg_lvl{level}', ax=axs[level-1], legend=True)\n",
    "    axs[level-1].set(yticklabels='', xticklabels='')\n",
    "    axs[level-1].set_title(f'Dissolved Oxygen\\nLevel = {level}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47d9cb0-06cf-41ed-965c-dcce568aa9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_yrAvg={}\n",
    "for depth_layer in range(1,11):\n",
    "    DO_yrAvg[depth_layer] = numpy.mean(DO[depth_layer],axis=0)\n",
    "    gdf[f'DO_yrAvg_lvl{depth_layer}'] = DO_yrAvg[depth_layer]\n",
    "    gdf.plot(f'DO_yrAvg_lvl{depth_layer}', figsize=(4,6), legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d7525-e1fe-47dd-959a-6d36ed5230db",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO[depth_layer].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4acda32-a8b2-48ef-936a-066364e8b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot('depth', figsize=(8,12), legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343102a-32e6-40c6-ab11-c7d891b3aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "[*gdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb7acb-34bd-4861-94b7-8cacd3324d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdf['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53728fa3-403b-4de8-a5ff-90fa2c103f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['node_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8165fa0c-3ccb-481a-8a60-ac37a149e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['node_id'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a37506-4ff8-4e40-947d-858c31809002",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_daily_min_xr[0].loc[model_output_daily_min_xr[0]['node_id']==gdf['node_id'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b8bee-29a3-42c1-b180-46e9fc182b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_daily_min_xr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f30dedc-aebe-4fad-8381-a75b79a795e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_daily_min_xr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d20aa3-c42b-4a03-a49f-2ab8ce45c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model_output_daily_min_xr[0].where((model_output_daily_min_xr[0].node_id.isin(gdf['node_id'])), drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6119133f-4d9b-4098-be98-431e74ddaca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188c23e-443f-48ab-a952-4cffa22315df",
   "metadata": {},
   "source": [
    "## Plot DO output \"as is\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a83babd-b09c-4d6f-bf33-14228928ba8e",
   "metadata": {},
   "source": [
    "## DO graphic (Extract Puget Sound DO from model output and plot)\n",
    "plot `model_output_daily_min_xr`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f4df2-04e7-4ea9-afc8-76c1876e9999",
   "metadata": {},
   "source": [
    "#### use the `node_id` values in `gdf` to select DO values from model output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2552ab-bb4f-4975-a766-88981a310d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_1day = model_output_daily_min_xr[0].where(\n",
    "    (model_output_daily_min_xr[0].node_id.isin(gdf['node_id'])), \n",
    "    drop=True\n",
    ")\n",
    "DO_1day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5265e54-23c2-400b-8d4d-c14b9ba3c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_1day.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4070b2-206d-44fd-8a66-6f7b682582df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = DO_1day['node_id'].to_dataframe()\n",
    "test['DO']=DO_1day.values\n",
    "test.pop('time_in_days')\n",
    "test.pop('node_id')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3cc5c-fdbc-4e9d-bb93-8bd93921d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = pandas.merge(\n",
    "    gdf,\n",
    "    test,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='node_id',\n",
    "    right_on='node_id',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b21e3ab-d291-4a50-ab1c-6289830dd26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b082c5-a7aa-490c-a323-5aef587aae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.plot('DO', figsize=(8,12), legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c76961e-be6c-4472-8d1c-b14f2ac1db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['DO_1day']=DO_1day.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213231be-4dfb-4844-a212-4546f8876fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot('DO_1day', figsize=(8,12), legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17441e35-4d81-46a3-99a3-9e002b6f88b5",
   "metadata": {},
   "source": [
    "### Well, that didn't work.  We aren't in the business of making dragons. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bee8ad-0bbc-4bcb-b456-ac71fc3ec383",
   "metadata": {},
   "source": [
    "# repeat the above with mean daily values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231006da-55ee-4658-a3fc-6dc4d710e57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# use range to easily adapt to multiple scenarios but only select the first one here\n",
    "for si in range(0, 1):\n",
    "    print(data_paths[si])\n",
    "    scenario_name=str(data_paths[si]).split('/')[-3]\n",
    "    # output netcdf filename\n",
    "    output_file = output_directory/f'{scenario_name}_{variable_name}.nc'\n",
    "    # input netcdf filename\n",
    "    file_path=data_paths[si]/'s_hy_base000_pnnl007_nodes.nc'\n",
    "    # load variable into xarray and calculate daily min.\n",
    "    # NOTE: For ease, I use original method with numpy and pandas but \n",
    "    #    it may be worth exploring ways to calculate the min in xarray format\n",
    "    with xarray.open_dataset(file_path) as ds:\n",
    "        model_output_daily=numpy.reshape(\n",
    "            ds[model_output_name[variable_name]][:,:].data, (365,24,160120)\n",
    "        )\n",
    "        model_output_daily_mean=numpy.mean(model_output_daily,axis=1)\n",
    "        model_output_daily_mean_pd=pandas.DataFrame(model_output_daily_mean)\n",
    "        # create a new xarray with min daily values\n",
    "        model_output_daily_mean_xr = xarray.DataArray(model_output_daily_mean_pd)\n",
    "        # rename the coordinates so they are human-readable\n",
    "        model_output_daily_mean_xr=model_output_daily_mean_xr.rename(\n",
    "            {'dim_0':'time_in_days', 'dim_1':'node_id'}\n",
    "        )\n",
    "        # model_output_daily_min_xr.to_netcdf(output_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef2b7e7-85e9-467f-b885-b7d3e6efad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.Var_10[:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e2214-e70f-44f7-bc4d-a1f764ac7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DO values for all nodes in gdf['node_id']\n",
    "DO_1day = model_output_daily_mean_xr[0].where(\n",
    "    (model_output_daily_min_xr[0].node_id.isin(gdf['node_id'])), \n",
    "    drop=True\n",
    ")\n",
    "# create dataframe\n",
    "df={}\n",
    "df['mean'] = DO_1day['node_id'].to_dataframe()\n",
    "df['mean']['DO']=DO_1day.values\n",
    "df['mean'].pop('time_in_days')\n",
    "df['mean'].pop('node_id')\n",
    "# merge model output with shapefile using \"node_id\" for merge\n",
    "gdf_merged = pandas.merge(\n",
    "    gdf,\n",
    "    df['mean'],\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='node_id',\n",
    "    right_on='node_id',\n",
    ")\n",
    "gdf_merged.plot('DO', figsize=(8,12), legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6f9fd-90e7-4143-9e86-088c6f49c1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410095ed-ebea-493f-b9c2-51417fc6628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31312239-fbca-4464-bd6f-ae2c086f71c1",
   "metadata": {},
   "source": [
    "## import .csv file with node information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4534fa2-ca58-49e4-89fe-2a77961cc4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path=pathlib.Path('/mmfs1/gscratch/ssmc/USRS/PSI/Sukyong/script')/'node_info.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a8c28e-b131-4509-90a6-1395493983da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coords = pandas.read_csv(csv_file_path, index_col='node_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b10ad-50e7-4380-bccb-c2f86a2923ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coords.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc88b9a8-27bf-45bb-9120-09325998c07f",
   "metadata": {},
   "source": [
    "#### merge the \"DO\" values with the coordinate information using node_id (index) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f44d5-17ba-4f99-9cf2-411611313835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coords_merged = pandas.merge(\n",
    "    df_coords,\n",
    "    df['mean'],\n",
    "    how=\"left\",\n",
    "    on='node_id',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea5473-e6c3-4239-8df4-e6ea50008594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coords_merged['DO']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77be6d0f-4d26-4308-86d3-9434bdad4aa6",
   "metadata": {},
   "source": [
    "#### Plot DO values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01afac99-5307-4528-b287-c5ff9067fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "ax.scatter(x=df_coords_merged['lon'], \n",
    "            y=df_coords_merged['lat'], \n",
    "            c=df_coords_merged['DO'],\n",
    "            s=12\n",
    "           )\n",
    "ax.set_aspect('equal',adjustable='box')#plt.axis('equal')\n",
    "plt.xlim([-123.5,-122])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c2b331-6adb-4a4f-86bc-84f936ff2920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
